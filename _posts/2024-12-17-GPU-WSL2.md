---
layout: post
title: Checking your GPU via WSL2
date: 2024-12-17 11:59:00-0400
description: A guide to help you identify your GPU and its specifications via Windows Subsystem for Linux 2 (WSL2).
tags: GPU WSL2 CUDA NVIDIA
categories: sample-posts external-services
giscus_comments: true
related_posts: false
featured: true
toc:
  beginning: true
---

## Checking your NVIDIA GPU via WSL2

Like many computer science enthusiasts, I had a dream to build a powerful desktop that would make even the most ardent gamers-or in my case, bioinformaticians-pause in admiration. So, I went ahead and purchased a powerhouse machine, armed with a high-performance GPU packed with CUDA cores, perfect for deep learning and computational analysis. I also aptly named it "The Beast". Yet, my precious Beast has been sitting idle (for nearly two years after purchase) when it comes to actual data analysis. Sound familiar? If you're a Windows user like me, sitting on untapped GPU potential, this is the guide for you on how to inspect your GPU via windows subsystem for linux 2 (WSL2). At least we got to start somewhere with harnessing the full potential of your NVIDIA GPU (most have NVIDIA GPUs, some have AMD GPUs) within the Windows ecosystem. Let me walk you through on inspecting your GPU via WSL2.
Please note that this guide is for NVIDIA GPUs. Similar alternatives exist for AMD GPUs.

### Step 1: Identifying Your GPU

To find out how many GPUs you have in WSL2, first, open your WSL2 terminal and check details using the `lspci` command.
you might try using the `lspci` command:

```bash
lspci | grep -i vga
```

`lspci` lists all the Peripheral Component Interconnect (PCI) devices in your system, which includes network cards, sound cards, and GPUs. The `grep -i vga` part filters the output to show only VGA-compatible devices, which typically include your GPU. However, this command doesn't always display your GPU in WSL2 (in my case as well).
In that case, using the `nvidia-smi` command ([alternative for AMD GPUs is `rocm-smi`](https://unix.stackexchange.com/questions/370510/nvidia-smi-equivalent-for-amd-apu)) is a more reliable way to check your GPU.

```bash
nvidia-smi
```

This command provides detailed information about your GPU, including its name, driver version, and memory usage. For example, a typical output might look like this:

```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2060        On  |   XXXXXX:XXX.XX:XX  On |                  N/A |
|  0%   45C    P8             13W /  170W |     817MiB /   6144MiB |      6%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
```

### Step 2: Understanding the Output

The `nvidia-smi` command reveals a wealth of information. The key sections to focus on include:

- The first row displays the **NVIDIA-SMI version**, **Driver Version**, and **CUDA Version**.
- **NVIDIA-SMI Version:** Indicates the version of the NVIDIA System Management Interface (SMI) tool you're using.
- **Driver Version and CUDA Version:** Ensures you have the right software for GPU-accelerated tasks.
- In the lower two rows, the upper row is the header, and the lower row is the actual data. This has information about the actual GPU Name, memory usage, GPU utilisation, etc.
- **GPU Details:** Shows the model (NVIDIA GeForce RTX 2060) and important metrics like temperature and power usage
- **Memory Usage:** Indicates how much GPU memory is used and available.
- **GPU Utilisation:** Provides insights into how much of your GPU's capacity is being used.

> üìù You can use other versions of the command - `nvidia-smi -L` to list the GPUs in your system and `nvidia-smi -q` to get detailed information about your GPU.

### Step 3: Counting Your GPU Cores

If you're curious about the number of CUDA cores in your GPU, while `nvidia-smi` doesn't directly provide this information, you can look up your GPU model's specifications. For instance, the [NVIDIA GeForce RTX 2060](https://www.google.com.au/search?q=NVIDIA+GeForce+RTX+2060+number+of+cores&newwindow=1&sca_esv=d8dafcc4ab3fc50a&sxsrf=ADLYWII8hMarNEZYed2PKUl4mFf4xsex_w%3A1735072723984&ei=0xtrZ9rfO7DLseMPma3H-QQ&ved=0ahUKEwialf3KocGKAxWwZWwGHZnWMU8Q4dUDCBA&uact=5&oq=NVIDIA+GeForce+RTX+2060+number+of+cores&gs_lp=Egxnd3Mtd2l6LXNlcnAiJ05WSURJQSBHZUZvcmNlIFJUWCAyMDYwIG51bWJlciBvZiBjb3JlczIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjILEAAYgAQYhgMYigUyCxAAGIAEGIYDGIoFMgsQABiABBiGAxiKBTIIEAAYogQYiQUyBRAAGO8FMgUQABjvBTIFEAAY7wVIwxtQVVi0GnADeAGQAQCYAe0FoAHYHaoBDTAuNS4yLjAuMi4wLjK4AQPIAQD4AQGYAg6gAqIfwgIFECEYoAHCAggQABgWGAoYHsICBxAhGKABGAqYAwCSBwszLjMuNC4wLjIuMqAHgEg&sclient=gws-wiz-serp) typically has **1920 CUDA cores**, **240 Tensor cores** and **30 RT cores**. Note that a GPU can have different types of cores, each serving a specific purpose:

- **CUDA Cores**: Versatile for general computation and rendering.
- **Tensor Cores**: Specialized for deep learning tasks, speeding up matrix-heavy operations.
- **RT Cores**: Focused on real-time ray tracing, revolutionizing visual realism in graphics.

You might want to find this information programmatically, for which you might need to rely on Python's numba module (open source compiler for translating Python and NumPy code into a fast machine code). Here's a Python script (thanks to [StackOverflow post](https://stackoverflow.com/questions/63823395/how-can-i-get-the-number-of-cuda-cores-in-my-gpu-using-python-and-numba)) that can help you **identify the number of CUDA cores** in your GPU:

```python
from numba import cuda

# Dictionary mapping compute capabilities to cores per SM
cc_cores_per_SM_dict = {
    (2, 0): 32,
    (2, 1): 48,
    (3, 0): 192,
    (3, 5): 192,
    (3, 7): 192,
    (5, 0): 128,
    (5, 2): 128,
    (6, 0): 64,
    (6, 1): 128,
    (7, 0): 64,
    (7, 5): 64,
    (8, 0): 64,
    (8, 6): 128,
    (8, 9): 128,
    (9, 0): 128
}

# Get the current device
device = cuda.get_current_device()

# Retrieve the number of SMs
num_sms = device.MULTIPROCESSOR_COUNT

# Retrieve the compute capability
compute_capability = device.compute_capability

# Get the number of cores per SM based on compute capability
cores_per_sm = cc_cores_per_SM_dict.get(compute_capability, "Unknown")

# Calculate total cores
if cores_per_sm != "Unknown":
    total_cores = cores_per_sm * num_sms
    print(f"GPU Compute Capability: {compute_capability}")
    print(f"Number of SMs: {num_sms}")
    print(f"Cores per SM: {cores_per_sm}")
    print(f"Total CUDA Cores: {total_cores}")
else:
    print(f"Compute capability {compute_capability} is not recognized.")
```

**SM** here in the code refers to Streaming Multiprocessor (SM) which is a fundamental unit of parallel processing in GPUs (analogous to cores in CPUs). Each SM contains multiple CUDA cores, along with other resources like shared memory and instruction schedulers. SMs are responsible for executing instructions and performing computations in parallel, making them crucial for the GPU's performance.

This script will help you identify the number of CUDA cores in your GPU. This is the output I got for my NVIDIA GeForce RTX 2060:

```
GPU Compute Capability: (7, 5)
Number of SMs: 30
Cores per SM: 64
Total CUDA Cores: 1920
```

With these steps, you can at least inspect your GPU and understand its specifications. This knowledge will be crucial as you dive into GPU-accelerated data analysis, machine learning, and other computational tasks. Happy computing!

### Additional Resources

- [GPU-accelerated ML Training with WSL](https://learn.microsoft.com/en-us/windows/ai/directml/gpu-accelerated-training)
- [`numba` documentation](https://numba.readthedocs.io/en/stable/index.html)
- [Numba for AMD ROC GPUs](https://numba.readthedocs.io/en/0.52.0/roc/index.html)
