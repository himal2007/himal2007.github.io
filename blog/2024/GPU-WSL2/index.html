<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="pAWiQy3GcLasYh5xN1AqW0Dc4fzeFvjZcw7TMuMk3UE"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Checing your GPU via WSL2 | Himal Shrestha </title> <meta name="author" content="Himal Shrestha"> <meta name="description" content="A guide to help you identify your GPU and its specifications via Windows Subsystem for Linux 2 (WSL2)."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://himal2007.github.io/blog/2024/GPU-WSL2/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Himal</span> Shrestha </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Checing your GPU via WSL2</h1> <p class="post-meta"> Created in December 17, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/gpu"> <i class="fa-solid fa-hashtag fa-sm"></i> GPU</a>   <a href="/blog/tag/wsl2"> <i class="fa-solid fa-hashtag fa-sm"></i> WSL2</a>   <a href="/blog/tag/cuda"> <i class="fa-solid fa-hashtag fa-sm"></i> CUDA</a>   <a href="/blog/tag/nvidia"> <i class="fa-solid fa-hashtag fa-sm"></i> NVIDIA</a>     ·   <a href="/blog/category/sample-posts"> <i class="fa-solid fa-tag fa-sm"></i> sample-posts</a>   <a href="/blog/category/external-services"> <i class="fa-solid fa-tag fa-sm"></i> external-services</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"> <a href="#checking-your-nvidia-gpu-via-wsl2">Checking your NVIDIA GPU via WSL2</a> <ul> <li class="toc-entry toc-h3"><a href="#step-1-identifying-your-gpu">Step 1: Identifying Your GPU</a></li> <li class="toc-entry toc-h3"><a href="#step-2-understanding-the-output">Step 2: Understanding the Output</a></li> <li class="toc-entry toc-h3"><a href="#step-3-counting-your-gpu-cores">Step 3: Counting Your GPU Cores</a></li> <li class="toc-entry toc-h3"><a href="#definitions">Definitions</a></li> <li class="toc-entry toc-h3"><a href="#additional-resources">Additional Resources</a></li> </ul> </li> </ul> </div> <hr> <div id="markdown-content"> <h2 id="checking-your-nvidia-gpu-via-wsl2">Checking your NVIDIA GPU via WSL2</h2> <p>Like many computer science enthusiasts, I had a dream to build a powerful desktop that would make even the most ardent gamers-or in my case, bioinformaticians-pause in admiration. So, I went ahead and purchased a powerhouse machine, armed with a high-performance GPU packed with CUDA cores, perfect for deep learning and computational analysis. I also aptly named it “The Beast”. Yet, my precious Beast has been sitting idle (for nearly two years after purchase) when it comes to actual data analysis. Sound familiar? If you’re a Windows user like me, sitting on untapped GPU potential, this is the guide for you on how to inspect your GPU via windows subsystem for linux 2 (WSL2). At least we got to start somewhere with harnessing the full potential of your NVIDIA GPU (most have NVIDIA GPUs, some have AMD GPUs) within the Windows ecosystem. Let me walk you through on inspecting your GPU via WSL2. Please note that this guide is for NVIDIA GPUs. Similar alternatives exist for AMD GPUs.</p> <h3 id="step-1-identifying-your-gpu">Step 1: Identifying Your GPU</h3> <p>To find out how many GPUs you have in WSL2, first, open your WSL2 terminal and check details using the <code class="language-plaintext highlighter-rouge">lspci</code> command. you might try using the <code class="language-plaintext highlighter-rouge">lspci</code> command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lspci | <span class="nb">grep</span> <span class="nt">-i</span> vga
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">lspci</code> lists all the Peripheral Component Interconnect (PCI) devices in your system, which includes network cards, sound cards, and GPUs. The <code class="language-plaintext highlighter-rouge">grep -i vga</code> part filters the output to show only VGA-compatible devices, which typically include your GPU. However, this command doesn’t always display your GPU in WSL2 (in my case as well). In that case, using the <code class="language-plaintext highlighter-rouge">nvidia-smi</code> command (<a href="https://unix.stackexchange.com/questions/370510/nvidia-smi-equivalent-for-amd-apu" rel="external nofollow noopener" target="_blank">alternative for AMD GPUs is <code class="language-plaintext highlighter-rouge">rocm-smi</code></a>) is a more reliable way to check your GPU.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvidia-smi
</code></pre></div></div> <p>This command provides detailed information about your GPU, including its name, driver version, and memory usage. For example, a typical output might look like this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2060        On  |   XXXXXX:XXX.XX:XX  On |                  N/A |
|  0%   45C    P8             13W /  170W |     817MiB /   6144MiB |      6%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
</code></pre></div></div> <h3 id="step-2-understanding-the-output">Step 2: Understanding the Output</h3> <p>The <code class="language-plaintext highlighter-rouge">nvidia-smi</code> command reveals a wealth of information. The key sections to focus on include:</p> <ul> <li>The first row displays the <strong>NVIDIA-SMI version</strong>, <strong>Driver Version</strong>, and <strong>CUDA Version</strong>.</li> <li> <strong>NVIDIA-SMI Version:</strong> Indicates the version of the NVIDIA System Management Interface (SMI) tool you’re using.</li> <li> <strong>Driver Version and CUDA Version:</strong> Ensures you have the right software for GPU-accelerated tasks.</li> <li>In the lower two rows, the upper row is the header, and the lower row is the actual data. This has information about the actual GPU Name, memory usage, GPU utilisation, etc.</li> <li> <strong>GPU Details:</strong> Shows the model (NVIDIA GeForce RTX 2060) and important metrics like temperature and power usage</li> <li> <strong>Memory Usage:</strong> Indicates how much GPU memory is used and available.</li> <li> <strong>GPU Utilisation:</strong> Provides insights into how much of your GPU’s capacity is being used.</li> </ul> <blockquote> <p>📝 You can use other versions of the command - <code class="language-plaintext highlighter-rouge">nvidia-smi -L</code> to list the GPUs in your system and <code class="language-plaintext highlighter-rouge">nvidia-smi -q</code> to get detailed information about your GPU.</p> </blockquote> <h3 id="step-3-counting-your-gpu-cores">Step 3: Counting Your GPU Cores</h3> <p>If you’re curious about the number of CUDA cores in your GPU, while <code class="language-plaintext highlighter-rouge">nvidia-smi</code> doesn’t directly provide this information, you can look up your GPU model’s specifications. For instance, the <a href="https://www.google.com.au/search?q=NVIDIA+GeForce+RTX+2060+number+of+cores&amp;newwindow=1&amp;sca_esv=d8dafcc4ab3fc50a&amp;sxsrf=ADLYWII8hMarNEZYed2PKUl4mFf4xsex_w%3A1735072723984&amp;ei=0xtrZ9rfO7DLseMPma3H-QQ&amp;ved=0ahUKEwialf3KocGKAxWwZWwGHZnWMU8Q4dUDCBA&amp;uact=5&amp;oq=NVIDIA+GeForce+RTX+2060+number+of+cores&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiJ05WSURJQSBHZUZvcmNlIFJUWCAyMDYwIG51bWJlciBvZiBjb3JlczIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjILEAAYgAQYhgMYigUyCxAAGIAEGIYDGIoFMgsQABiABBiGAxiKBTIIEAAYogQYiQUyBRAAGO8FMgUQABjvBTIFEAAY7wVIwxtQVVi0GnADeAGQAQCYAe0FoAHYHaoBDTAuNS4yLjAuMi4wLjK4AQPIAQD4AQGYAg6gAqIfwgIFECEYoAHCAggQABgWGAoYHsICBxAhGKABGAqYAwCSBwszLjMuNC4wLjIuMqAHgEg&amp;sclient=gws-wiz-serp" rel="external nofollow noopener" target="_blank">NVIDIA GeForce RTX 2060</a> typically has <strong>1920 CUDA cores</strong>, <strong>240 Tensor cores</strong> and <strong>30 RT cores</strong>. Note that a GPU can have different types of cores, each serving a specific purpose:</p> <ul> <li> <strong>CUDA Cores</strong>: Versatile for general computation and rendering.</li> <li> <strong>Tensor Cores</strong>: Specialized for deep learning tasks, speeding up matrix-heavy operations.</li> <li> <strong>RT Cores</strong>: Focused on real-time ray tracing, revolutionizing visual realism in graphics.</li> </ul> <p>You might want to find this information programmatically, for which you might need to rely on Python’s numba module (open source compiler for translating Python and NumPy code into a fast machine code). Here’s a Python script (thanks to <a href="https://stackoverflow.com/questions/63823395/how-can-i-get-the-number-of-cuda-cores-in-my-gpu-using-python-and-numba" rel="external nofollow noopener" target="_blank">StackOverflow post</a>) that can help you <strong>identify the number of CUDA cores</strong> in your GPU:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="c1"># Dictionary mapping compute capabilities to cores per SM
</span><span class="n">cc_cores_per_SM_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">32</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">48</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">192</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span> <span class="mi">192</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span> <span class="mi">192</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">128</span>
<span class="p">}</span>

<span class="c1"># Get the current device
</span><span class="n">device</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">.</span><span class="nf">get_current_device</span><span class="p">()</span>

<span class="c1"># Retrieve the number of SMs
</span><span class="n">num_sms</span> <span class="o">=</span> <span class="n">device</span><span class="p">.</span><span class="n">MULTIPROCESSOR_COUNT</span>

<span class="c1"># Retrieve the compute capability
</span><span class="n">compute_capability</span> <span class="o">=</span> <span class="n">device</span><span class="p">.</span><span class="n">compute_capability</span>

<span class="c1"># Get the number of cores per SM based on compute capability
</span><span class="n">cores_per_sm</span> <span class="o">=</span> <span class="n">cc_cores_per_SM_dict</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">compute_capability</span><span class="p">,</span> <span class="sh">"</span><span class="s">Unknown</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Calculate total cores
</span><span class="k">if</span> <span class="n">cores_per_sm</span> <span class="o">!=</span> <span class="sh">"</span><span class="s">Unknown</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">total_cores</span> <span class="o">=</span> <span class="n">cores_per_sm</span> <span class="o">*</span> <span class="n">num_sms</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">GPU Compute Capability: </span><span class="si">{</span><span class="n">compute_capability</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of SMs: </span><span class="si">{</span><span class="n">num_sms</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Cores per SM: </span><span class="si">{</span><span class="n">cores_per_sm</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Total CUDA Cores: </span><span class="si">{</span><span class="n">total_cores</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Compute capability </span><span class="si">{</span><span class="n">compute_capability</span><span class="si">}</span><span class="s"> is not recognized.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><strong>SM</strong> here in the code refers to Streaming Multiprocessor (SM) which is a fundamental unit of parallel processing in GPUs (analogous to cores in CPUs). Each SM contains multiple CUDA cores, along with other resources like shared memory and instruction schedulers. SMs are responsible for executing instructions and performing computations in parallel, making them crucial for the GPU’s performance.</p> <p>This script will help you identify the number of CUDA cores in your GPU. This is the output I got for my NVIDIA GeForce RTX 2060:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GPU Compute Capability: (7, 5)
Number of SMs: 30
Cores per SM: 64
Total CUDA Cores: 1920
</code></pre></div></div> <p>With these steps, you can at least inspect your GPU and understand its specifications. This knowledge will be crucial as you dive into GPU-accelerated data analysis, machine learning, and other computational tasks. Happy computing!</p> <h3 id="definitions">Definitions</h3> <p>There are mutliple types of cores in a GPU. It’s good to be aware of the different types of cores in a GPU.</p> <h3 id="additional-resources">Additional Resources</h3> <ul> <li><a href="https://learn.microsoft.com/en-us/windows/ai/directml/gpu-accelerated-training" rel="external nofollow noopener" target="_blank">GPU-accelerated ML Training with WSL</a></li> <li> <code class="language-plaintext highlighter-rouge">[numba</code> documentation](https://numba.readthedocs.io/en/stable/index.html)</li> <li><a href="https://numba.readthedocs.io/en/0.52.0/roc/index.html?utm_source=chatgpt.com" rel="external nofollow noopener" target="_blank">Numba for AMD ROC GPUs</a></li> </ul> </div> </article> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"himal2007/himal2007.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Himal Shrestha. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: December 27, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-TFED2ZNFCK"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-TFED2ZNFCK");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>