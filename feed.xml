<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://himal2007.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://himal2007.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-27T21:23:50+00:00</updated><id>https://himal2007.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Checing your GPU via WSL2</title><link href="https://himal2007.github.io/blog/2024/GPU-WSL2/" rel="alternate" type="text/html" title="Checing your GPU via WSL2"/><published>2024-12-17T15:59:00+00:00</published><updated>2024-12-17T15:59:00+00:00</updated><id>https://himal2007.github.io/blog/2024/GPU-WSL2</id><content type="html" xml:base="https://himal2007.github.io/blog/2024/GPU-WSL2/"><![CDATA[<h2 id="checking-your-nvidia-gpu-via-wsl2">Checking your NVIDIA GPU via WSL2</h2> <p>Like many computer science enthusiasts, I had a dream to build a powerful desktop that would make even the most ardent gamers-or in my case, bioinformaticians-pause in admiration. So, I went ahead and purchased a powerhouse machine, armed with a high-performance GPU packed with CUDA cores, perfect for deep learning and computational analysis. I also aptly named it ‚ÄúThe Beast‚Äù. Yet, my precious Beast has been sitting idle (for nearly two years after purchase) when it comes to actual data analysis. Sound familiar? If you‚Äôre a Windows user like me, sitting on untapped GPU potential, this is the guide for you on how to inspect your GPU via windows subsystem for linux 2 (WSL2). At least we got to start somewhere with harnessing the full potential of your NVIDIA GPU (most have NVIDIA GPUs, some have AMD GPUs) within the Windows ecosystem. Let me walk you through on inspecting your GPU via WSL2. Please note that this guide is for NVIDIA GPUs. Similar alternatives exist for AMD GPUs.</p> <h3 id="step-1-identifying-your-gpu">Step 1: Identifying Your GPU</h3> <p>To find out how many GPUs you have in WSL2, first, open your WSL2 terminal and check details using the <code class="language-plaintext highlighter-rouge">lspci</code> command. you might try using the <code class="language-plaintext highlighter-rouge">lspci</code> command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lspci | <span class="nb">grep</span> <span class="nt">-i</span> vga
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">lspci</code> lists all the Peripheral Component Interconnect (PCI) devices in your system, which includes network cards, sound cards, and GPUs. The <code class="language-plaintext highlighter-rouge">grep -i vga</code> part filters the output to show only VGA-compatible devices, which typically include your GPU. However, this command doesn‚Äôt always display your GPU in WSL2 (in my case as well). In that case, using the <code class="language-plaintext highlighter-rouge">nvidia-smi</code> command (<a href="https://unix.stackexchange.com/questions/370510/nvidia-smi-equivalent-for-amd-apu">alternative for AMD GPUs is <code class="language-plaintext highlighter-rouge">rocm-smi</code></a>) is a more reliable way to check your GPU.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvidia-smi
</code></pre></div></div> <p>This command provides detailed information about your GPU, including its name, driver version, and memory usage. For example, a typical output might look like this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2060        On  |   XXXXXX:XXX.XX:XX  On |                  N/A |
|  0%   45C    P8             13W /  170W |     817MiB /   6144MiB |      6%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
</code></pre></div></div> <h3 id="step-2-understanding-the-output">Step 2: Understanding the Output</h3> <p>The <code class="language-plaintext highlighter-rouge">nvidia-smi</code> command reveals a wealth of information. The key sections to focus on include:</p> <ul> <li>The first row displays the <strong>NVIDIA-SMI version</strong>, <strong>Driver Version</strong>, and <strong>CUDA Version</strong>.</li> <li><strong>NVIDIA-SMI Version:</strong> Indicates the version of the NVIDIA System Management Interface (SMI) tool you‚Äôre using.</li> <li><strong>Driver Version and CUDA Version:</strong> Ensures you have the right software for GPU-accelerated tasks.</li> <li>In the lower two rows, the upper row is the header, and the lower row is the actual data. This has information about the actual GPU Name, memory usage, GPU utilisation, etc.</li> <li><strong>GPU Details:</strong> Shows the model (NVIDIA GeForce RTX 2060) and important metrics like temperature and power usage</li> <li><strong>Memory Usage:</strong> Indicates how much GPU memory is used and available.</li> <li><strong>GPU Utilisation:</strong> Provides insights into how much of your GPU‚Äôs capacity is being used.</li> </ul> <blockquote> <p>üìù You can use other versions of the command - <code class="language-plaintext highlighter-rouge">nvidia-smi -L</code> to list the GPUs in your system and <code class="language-plaintext highlighter-rouge">nvidia-smi -q</code> to get detailed information about your GPU.</p> </blockquote> <h3 id="step-3-counting-your-gpu-cores">Step 3: Counting Your GPU Cores</h3> <p>If you‚Äôre curious about the number of CUDA cores in your GPU, while <code class="language-plaintext highlighter-rouge">nvidia-smi</code> doesn‚Äôt directly provide this information, you can look up your GPU model‚Äôs specifications. For instance, the <a href="https://www.google.com.au/search?q=NVIDIA+GeForce+RTX+2060+number+of+cores&amp;newwindow=1&amp;sca_esv=d8dafcc4ab3fc50a&amp;sxsrf=ADLYWII8hMarNEZYed2PKUl4mFf4xsex_w%3A1735072723984&amp;ei=0xtrZ9rfO7DLseMPma3H-QQ&amp;ved=0ahUKEwialf3KocGKAxWwZWwGHZnWMU8Q4dUDCBA&amp;uact=5&amp;oq=NVIDIA+GeForce+RTX+2060+number+of+cores&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiJ05WSURJQSBHZUZvcmNlIFJUWCAyMDYwIG51bWJlciBvZiBjb3JlczIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjILEAAYgAQYhgMYigUyCxAAGIAEGIYDGIoFMgsQABiABBiGAxiKBTIIEAAYogQYiQUyBRAAGO8FMgUQABjvBTIFEAAY7wVIwxtQVVi0GnADeAGQAQCYAe0FoAHYHaoBDTAuNS4yLjAuMi4wLjK4AQPIAQD4AQGYAg6gAqIfwgIFECEYoAHCAggQABgWGAoYHsICBxAhGKABGAqYAwCSBwszLjMuNC4wLjIuMqAHgEg&amp;sclient=gws-wiz-serp">NVIDIA GeForce RTX 2060</a> typically has <strong>1920 CUDA cores</strong>, <strong>240 Tensor cores</strong> and <strong>30 RT cores</strong>. Note that a GPU can have different types of cores, each serving a specific purpose:</p> <ul> <li><strong>CUDA Cores</strong>: Versatile for general computation and rendering.</li> <li><strong>Tensor Cores</strong>: Specialized for deep learning tasks, speeding up matrix-heavy operations.</li> <li><strong>RT Cores</strong>: Focused on real-time ray tracing, revolutionizing visual realism in graphics.</li> </ul> <p>You might want to find this information programmatically, for which you might need to rely on Python‚Äôs numba module (open source compiler for translating Python and NumPy code into a fast machine code). Here‚Äôs a Python script (thanks to <a href="https://stackoverflow.com/questions/63823395/how-can-i-get-the-number-of-cuda-cores-in-my-gpu-using-python-and-numba">StackOverflow post</a>) that can help you <strong>identify the number of CUDA cores</strong> in your GPU:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="c1"># Dictionary mapping compute capabilities to cores per SM
</span><span class="n">cc_cores_per_SM_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">32</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">48</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">192</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span> <span class="mi">192</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span> <span class="mi">192</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">):</span> <span class="mi">128</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">128</span>
<span class="p">}</span>

<span class="c1"># Get the current device
</span><span class="n">device</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">.</span><span class="nf">get_current_device</span><span class="p">()</span>

<span class="c1"># Retrieve the number of SMs
</span><span class="n">num_sms</span> <span class="o">=</span> <span class="n">device</span><span class="p">.</span><span class="n">MULTIPROCESSOR_COUNT</span>

<span class="c1"># Retrieve the compute capability
</span><span class="n">compute_capability</span> <span class="o">=</span> <span class="n">device</span><span class="p">.</span><span class="n">compute_capability</span>

<span class="c1"># Get the number of cores per SM based on compute capability
</span><span class="n">cores_per_sm</span> <span class="o">=</span> <span class="n">cc_cores_per_SM_dict</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">compute_capability</span><span class="p">,</span> <span class="sh">"</span><span class="s">Unknown</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Calculate total cores
</span><span class="k">if</span> <span class="n">cores_per_sm</span> <span class="o">!=</span> <span class="sh">"</span><span class="s">Unknown</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">total_cores</span> <span class="o">=</span> <span class="n">cores_per_sm</span> <span class="o">*</span> <span class="n">num_sms</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">GPU Compute Capability: </span><span class="si">{</span><span class="n">compute_capability</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of SMs: </span><span class="si">{</span><span class="n">num_sms</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Cores per SM: </span><span class="si">{</span><span class="n">cores_per_sm</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Total CUDA Cores: </span><span class="si">{</span><span class="n">total_cores</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Compute capability </span><span class="si">{</span><span class="n">compute_capability</span><span class="si">}</span><span class="s"> is not recognized.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><strong>SM</strong> here in the code refers to Streaming Multiprocessor (SM) which is a fundamental unit of parallel processing in GPUs (analogous to cores in CPUs). Each SM contains multiple CUDA cores, along with other resources like shared memory and instruction schedulers. SMs are responsible for executing instructions and performing computations in parallel, making them crucial for the GPU‚Äôs performance.</p> <p>This script will help you identify the number of CUDA cores in your GPU. This is the output I got for my NVIDIA GeForce RTX 2060:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GPU Compute Capability: (7, 5)
Number of SMs: 30
Cores per SM: 64
Total CUDA Cores: 1920
</code></pre></div></div> <p>With these steps, you can at least inspect your GPU and understand its specifications. This knowledge will be crucial as you dive into GPU-accelerated data analysis, machine learning, and other computational tasks. Happy computing!</p> <h3 id="definitions">Definitions</h3> <p>There are mutliple types of cores in a GPU. It‚Äôs good to be aware of the different types of cores in a GPU.</p> <h3 id="additional-resources">Additional Resources</h3> <ul> <li><a href="https://learn.microsoft.com/en-us/windows/ai/directml/gpu-accelerated-training">GPU-accelerated ML Training with WSL</a></li> <li><code class="language-plaintext highlighter-rouge">[numba</code> documentation](https://numba.readthedocs.io/en/stable/index.html)</li> <li><a href="https://numba.readthedocs.io/en/0.52.0/roc/index.html?utm_source=chatgpt.com">Numba for AMD ROC GPUs</a></li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="external-services"/><category term="GPU"/><category term="WSL2"/><category term="CUDA"/><category term="NVIDIA"/><summary type="html"><![CDATA[A guide to help you identify your GPU and its specifications via Windows Subsystem for Linux 2 (WSL2).]]></summary></entry><entry><title type="html">Creating Flowcharts with Mermaid</title><link href="https://himal2007.github.io/blog/2024/mermaid/" rel="alternate" type="text/html" title="Creating Flowcharts with Mermaid"/><published>2024-06-04T17:05:00+00:00</published><updated>2024-06-04T17:05:00+00:00</updated><id>https://himal2007.github.io/blog/2024/mermaid</id><content type="html" xml:base="https://himal2007.github.io/blog/2024/mermaid/"><![CDATA[<h1 id="creating-flowcharts-with-mermaid">Creating Flowcharts with Mermaid</h1> <p>Flowcharts are an integral part of my work. Whether it‚Äôs mapping out processes, planning projects, or visualizing ideas, a good flowchart can make all the difference. Over time, I‚Äôve experimented with various tools to create these diagrams. Here, I want to share my experience with Mermaid, a powerful tool for creating flowcharts and other diagrams using simple code.</p> <h2 id="the-hunt-for-the-perfect-flowchart-tool">The Hunt for the Perfect Flowchart Tool</h2> <p>I‚Äôve tried several tools in my quest for the perfect flowchart creator. Here are some honorable mentions:</p> <ul> <li><strong>draw.io</strong>: A versatile and user-friendly diagramming tool.</li> <li><strong>Excalidraw</strong>: Great for hand-drawn style diagrams and recently added support for Mermaid.</li> <li><strong>Lucidchart</strong>: A robust, professional-grade diagramming application.</li> </ul> <p>These tools are fantastic, but I needed something that could be seamlessly embedded within markdown documents, which led me to discover Mermaid.</p> <h2 id="what-is-mermaid">What is Mermaid?</h2> <p>Mermaid is a tool that allows you to create diagrams and visualizations using a simple and easy-to-read code syntax. It‚Äôs particularly useful for embedding within markdown documents, making it perfect for documentation and collaborative projects.</p> <h3 id="why-mermaid">Why Mermaid?</h3> <ol> <li><strong>Markdown Integration</strong>: Mermaid lets you embed flowcharts directly within your markdown files. This keeps everything in one place and makes your documents more dynamic and interactive.</li> <li><strong>Code-based Diagrams</strong>: With Mermaid, you write diagrams as code. This approach is not only efficient but also allows for version control and easy updates.</li> <li><strong>Versatility</strong>: Beyond flowcharts, Mermaid supports Gantt charts, sequence diagrams, class diagrams, and more.</li> </ol> <h3 id="creating-a-flowchart-with-mermaid">Creating a Flowchart with Mermaid</h3> <p>Here‚Äôs an example of how you can create a simple flowchart using Mermaid:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">mermaid
</span><span class="sb">graph TD
    A[Start] --&gt; B{Is it working?}
    B --&gt;|Yes| C[Continue]
    B --&gt;|No| D[Fix it]
    D --&gt; B</span>
<span class="p">```</span>
</code></pre></div></div> <p>This code snippet generates a flowchart below with decision points and actions. Make sure to add to add <code class="language-plaintext highlighter-rouge">mermaid</code> tag in the code block to enable Mermaid rendering. Also, you need to enable Mermaid rendering in the YAML front matter of your markdown file with <code class="language-plaintext highlighter-rouge">mermaid: enabled: true</code>.</p> <pre><code class="language-mermaid">graph TD
    A[Start] --&gt; B{Is it working?}
    B --&gt;|Yes| C[Continue]
    B --&gt;|No| D[Fix it]
    D --&gt; B
</code></pre> <h2 id="exporting-charts">Exporting Charts</h2> <p>One of my initial concerns was how to export these charts in high-quality formats like PDF or PNG. Thankfully, I found the <strong>Mermaid Live Editor</strong>. This online tool allows you to create, preview, and export your Mermaid diagrams easily. It‚Äôs very similar to Leaflet and operates on a freemium model.</p> <h2 id="interactive-features">Interactive Features</h2> <p>When rendered within a markdown document, Mermaid charts offer neat interactive features:</p> <ul> <li><strong>Zoom</strong>: Easily zoom in and out to focus on different parts of your chart.</li> <li><strong>Rotate</strong>: Rotate your diagrams to get a better view or fit them into your layout.</li> </ul> <h2 id="extra-capabilities-with-mermaid">Extra Capabilities with Mermaid</h2> <p>Mermaid is continuously evolving, and there are several additional features worth mentioning:</p> <ul> <li><strong>Integration with Excalidraw</strong>: Excalidraw now supports Mermaid, allowing you to combine hand-drawn elements with code-based diagrams.</li> <li><strong>AI Features</strong>: Tools like GitHub Copilot can help you generate flowcharts from text descriptions. For example, using <a href="https://github.com/marketplace/actions/export-mermaidjs-erdiagrams-from-database">this GitHub Action</a>, you can convert database schemas to ER diagrams with ease.</li> <li><strong>Image Conversion</strong>: You can even convert images into flowcharts using advanced AI capabilities.</li> </ul> <p>In conclusion, Mermaid is a fantastic tool for anyone who needs to create and embed flowcharts and other diagrams within markdown documents. It‚Äôs easy to use, highly versatile, and offers excellent integration with other tools and platforms. If you‚Äôre in the market for a flowchart tool, give Mermaid a try ‚Äì it might just be the perfect solution for your needs!</p>]]></content><author><name></name></author><category term="tools"/><category term="flowcharts"/><category term="mermaid"/><summary type="html"><![CDATA[My experience with mermaid for creating flowcharts and diagrams using simple code.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://himal2007.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://himal2007.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://himal2007.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">a post with code</title><link href="https://himal2007.github.io/blog/2015/code/" rel="alternate" type="text/html" title="a post with code"/><published>2015-07-15T15:09:00+00:00</published><updated>2015-07-15T15:09:00+00:00</updated><id>https://himal2007.github.io/blog/2015/code</id><content type="html" xml:base="https://himal2007.github.io/blog/2015/code/"><![CDATA[<p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in markdown code tags:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">c++
</span><span class="n">code</span> <span class="n">code</span> <span class="n">code</span>
<span class="p">```</span>
</code></pre></div></div> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>For displaying code in a list item, you have to be aware of the indentation, as stated in this <a href="https://stackoverflow.com/questions/34987908/embed-a-code-block-in-a-list-item-with-proper-indentation-in-kramdown/38090598#38090598">Stackoverflow answer</a>. You must indent your code by <strong>(3 * bullet_indent_level)</strong> spaces. This is because kramdown (the markdown engine used by Jekyll) indentation for the code block in lists is determined by the column number of the first non-space character after the list item marker. For example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">1.</span> We can put fenced code blocks inside nested bullets, too.
<span class="p">
   1.</span> Like this:<span class="sb">

      ```c
      printf("Hello, World!");
      ```

</span><span class="p">   2.</span> The key is to indent your fenced block in the same line as the first character of the line.
</code></pre></div></div> <p>Which displays:</p> <ol> <li> <p>We can put fenced code blocks inside nested bullets, too.</p> <ol> <li> <p>Like this:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">printf</span><span class="p">(</span><span class="s">"Hello, World!"</span><span class="p">);</span>
</code></pre></div> </div> </li> <li> <p>The key is to indent your fenced block in the same line as the first character of the line.</p> </li> </ol> </li> </ol> <p>By default, it does not display line numbers. If you want to display line numbers for every code block, you can set <code class="language-plaintext highlighter-rouge">kramdown.syntax_highlighter_opts.block.line_numbers</code> to true in your <code class="language-plaintext highlighter-rouge">_config.yml</code> file.</p> <p>If you want to display line numbers for a specific code block, all you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. Produces something like this:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="code"><pre><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>

<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></figure>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[an example of a blog post with some code]]></summary></entry><entry><title type="html">a post with images</title><link href="https://himal2007.github.io/blog/2015/images/" rel="alternate" type="text/html" title="a post with images"/><published>2015-05-15T21:01:00+00:00</published><updated>2015-05-15T21:01:00+00:00</updated><id>https://himal2007.github.io/blog/2015/images</id><content type="html" xml:base="https://himal2007.github.io/blog/2015/images/"><![CDATA[<p>This is an example post with image galleries.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9-480.webp 480w,/assets/img/9-800.webp 800w,/assets/img/9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7-480.webp 480w,/assets/img/7-800.webp 800w,/assets/img/7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <p>Images can be made zoomable. Simply add <code class="language-plaintext highlighter-rouge">data-zoomable</code> to <code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> tags that you want to make zoomable.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8-480.webp 480w,/assets/img/8-800.webp 800w,/assets/img/8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10-480.webp 480w,/assets/img/10-800.webp 800w,/assets/img/10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The rest of the images in this post are all zoomable, arranged into different mini-galleries.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11-480.webp 480w,/assets/img/11-800.webp 800w,/assets/img/11-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/12-480.webp 480w,/assets/img/12-800.webp 800w,/assets/img/12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/12.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7-480.webp 480w,/assets/img/7-800.webp 800w,/assets/img/7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included images could look like]]></summary></entry><entry><title type="html">a post with formatting and links</title><link href="https://himal2007.github.io/blog/2015/formatting-and-links/" rel="alternate" type="text/html" title="a post with formatting and links"/><published>2015-03-15T16:40:16+00:00</published><updated>2015-03-15T16:40:16+00:00</updated><id>https://himal2007.github.io/blog/2015/formatting-and-links</id><content type="html" xml:base="https://himal2007.github.io/blog/2015/formatting-and-links/"><![CDATA[<p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h4 id="hipster-list">Hipster list</h4> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> <h4 id="check-list">Check List</h4> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Brush Teeth</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Put on socks <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Put on left sock</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Put on right sock</li> </ul> </li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Go to school</li> </ul> <p>Hoodie Thundercats retro, tote bag 8-bit Godard craft beer gastropub. Truffaut Tumblr taxidermy, raw denim Kickstarter sartorial dreamcatcher. Quinoa chambray slow-carb salvia readymade, bicycle rights 90‚Äôs yr typewriter selfies letterpress cardigan vegan.</p> <hr/> <p>Pug heirloom High Life vinyl swag, single-origin coffee four dollar toast taxidermy reprehenderit fap distillery master cleanse locavore. Est anim sapiente leggings Brooklyn ea. Thundercats locavore excepteur veniam eiusmod. Raw denim Truffaut Schlitz, migas sapiente Portland VHS twee Bushwick Marfa typewriter retro id keytar.</p> <blockquote> <p>We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. ‚ÄîAnais Nin</p> </blockquote> <p>Fap aliqua qui, scenester pug Echo Park polaroid irony shabby chic ex cardigan church-key Odd Future accusamus. Blog stumptown sartorial squid, gastropub duis aesthetic Truffaut vero. Pinterest tilde twee, odio mumblecore jean shorts lumbersexual.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="links"/><summary type="html"><![CDATA[march & april, looking forward to summer]]></summary></entry></feed>